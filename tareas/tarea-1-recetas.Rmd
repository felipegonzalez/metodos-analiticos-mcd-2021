---
title: "Análisis de ingredientes en recetas"
output: html_notebook
---

Análisis de
https://www.nature.com/articles/srep00196.pdf

Podemos usar *read_lines_chunked* si el archivo original es grande. En
este ejemplo, filtramos las recetas  *East Asian*:

```{r, message = FALSE}
library(tidyverse)

limpiar <- function(lineas,...){
  str_split(lineas, ',') %>% 
    keep(~.x[1] == 'EastAsian') %>%
    map(~.x[-1]) %>% # quitar tipo de cocina
    map(~.x[nchar(.x) > 0]) # quitar elementos vacios
}
callback_limpiar <- ListCallback$new(limpiar)
filtrado <- read_lines_chunked('../datos/recetas/srep00196-s3.csv',
                    skip = 1, callback = callback_limpiar, chunk_size = 1000)
recetas <-  filtrado %>% flatten
```

```{r}
recetas[1:10]
```


```{r, message=FALSE, warning=FALSE}
library(arules)
length(recetas)
## No hacer mucho más chico que este soporte, pues tenemos relativamente
## pocas transacciones:
pars <- list(support = 0.05,  target = 'frequent itemsets',
             ext = TRUE)
ap_recetas <- apriori(recetas, parameter = pars)
length(ap_recetas)
```

Vemos los items frecuentes

```{r}
frecs <- ap_recetas %>% subset(size(.) == 1 ) %>% sort(by = 'support') %>%
 DATAFRAME
DT::datatable(frecs %>% mutate_if(is.numeric, function(x) round(x, 3)))
```

Y ahora examinamos combinaciones frecuentes de distintos tamaños

```{r}
ap_recetas %>% 
  subset(size(.) == 2) %>%
  subset(support > 0.20) %>%
  sort(by = 'support') %>%
  inspect
```

Incluso hay algunas combinaciones de 4 ingredientes que ocurren con frecuencia alta:
estos ingredientes son bases de salsas, combinaciones de condimentos:

```{r}
ap_recetas %>% 
  subset(size(.) == 4) %>%
  subset(support > 0.10) %>%
  sort(by = 'support') %>%
  inspect
```

## Extracción de reglas

```{r}
pars <- list(support = 0.01, confidence = 0.10,
             target = 'rules',
             ext = TRUE)
reglas_recetas <- apriori(recetas, parameter = pars)
```

```{r}
agregar_hyperlift <- function(reglas, trans){
  quality(reglas) <- cbind(quality(reglas), 
	hyper_lift = interestMeasure(reglas, measure = "hyperLift", 
	transactions = trans))
  reglas
}
reglas_recetas <- agregar_hyperlift(reglas_recetas, recetas)
```


## Análisis de pares comunes

```{r}
library(arulesViz)
reglas_1 <- subset(reglas_recetas, hyper_lift > 1.1 & support > 0.1 & confidence > 0.40)
length(reglas_1)
reglas_tam_2 <- subset(reglas_1, size(reglas_1)==2)
#inspect(reglas_tam_2 %>% sort(by = 'hyper_lift')) 
plot(reglas_1 %>% subset(support > 0.2), engine = "plotly")
```

```{r, fig.width=10, fig.height=8}
library(tidygraph)
library(ggraph)
frecs <- 
df_reglas <- reglas_tam_2 %>% DATAFRAME %>% rename(from=LHS, to=RHS) %>% data.frame
df_reglas$weight <- log(df_reglas$lift)
graph_1 <- as_tbl_graph(df_reglas) %>%
  mutate(centrality = centrality_degree(mode = "all")) 
set.seed(881)
ggraph(graph_1, layout = 'fr') +
  geom_edge_link(aes(alpha=lift), 
                 colour = 'red',
                 arrow = arrow(length = unit(4, 'mm'))) + 
  geom_node_point(aes(size = centrality, colour = centrality)) + 
  geom_node_text(aes(label = name), size=4,
                 colour = 'gray20', repel=TRUE) +
  theme_graph(base_family = "sans")
```


```{r}
reglas_1 <- subset(reglas_recetas, hyper_lift > 1.5 & confidence > 0.1)
length(reglas_1)
reglas_tam_2 <- subset(reglas_1, size(reglas_1)==2)
length(reglas_tam_2)
```

```{r, fig.width=10, fig.height=8}
library(tidygraph)
library(ggraph)
df_reglas <- reglas_tam_2 %>% DATAFRAME %>% rename(from=LHS, to=RHS) %>% as_data_frame
df_reglas$weight <- log(df_reglas$hyper_lift)
graph_1 <- as_tbl_graph(df_reglas) %>%
  mutate(centrality = centrality_degree(mode = "all")) 

ggraph(graph_1, layout = 'fr', start.temp=100) +
  geom_edge_link(aes(alpha=lift), 
                 colour = 'red',
                 arrow = arrow(length = unit(4, 'mm'))) + 
  geom_node_point(aes(size = centrality, colour = centrality)) + 
  geom_node_text(aes(label = name), size=4,
                 colour = 'gray20', repel=TRUE) +
  theme_graph(base_family = "sans")
```

Exportamos para examinar en Gephi:


```{r}
write_csv(df_reglas %>% rename(source=from, target=to) %>%
            select(-count), 
          path='reglas.csv')
```


### Nota

La combinación _corn_ y _starch_ puede deberse en parte a una separación incorrecta en el 
procesamiento de los datos (corn starch o maizena convertido en dos ingredientes, corn y starch):

```{r}
df_reglas %>% filter(from == "{corn}", to == "{starch}")
```

La confianza es considerablemente alta, aunque tenemos pocos datos de esta combinación. Podemos examinar algunos ejemplos:

```{r}
recetas %>% keep(~ "tomato" %in% .x & "corn" %in% .x) %>% head(10)
```


